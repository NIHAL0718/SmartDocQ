"""API endpoints for question answering functionality."""

from typing import List, Optional
from fastapi import APIRouter, HTTPException, Query, Body
from pydantic import BaseModel

from app.services.qa_service import answer_question
from app.services.vector_store import search_similar_chunks
from app.models.qa import QuestionRequest, AnswerResponse, SourceChunk

router = APIRouter()


@router.post("/ask", response_model=AnswerResponse)
async def ask_question(request: QuestionRequest):
    """Answer a question based on document content."""
    try:
        # Get relevant document chunks
        relevant_chunks = search_similar_chunks(
            query=request.question,
            doc_id=request.doc_id,
            limit=request.max_sources or 5,
        )
        
        # Generate answer using LLM
        answer, sources = answer_question(
            question=request.question,
            context_chunks=relevant_chunks,
            language=request.language or "english",
            chat_history=request.chat_history,
        )
        
        return AnswerResponse(
            answer=answer,
            sources=sources,
            doc_id=request.doc_id,
            question=request.question,
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/voice", response_model=AnswerResponse)
async def voice_question(audio_file: bytes = Body(...), doc_id: str = Body(...), language: str = Body("english")):
    """Process voice question and return answer with audio."""
    try:
        # This would typically:
        # 1. Convert audio to text using speech recognition
        # 2. Process the question as in the /ask endpoint
        # 3. Convert the answer text to speech
        # 4. Return both text and audio
        
        # For now, return a mock response
        return AnswerResponse(
            answer="This is a mock answer to your voice question. In a real implementation, this would be generated by the LLM based on your spoken question.",
            sources=[
                SourceChunk(
                    text="Mock source text",
                    source="Document section 1.2",
                    relevance_score=0.95,
                )
            ],
            doc_id=doc_id,
            question="What was your voice question about?",
            audio_answer_url="/api/audio/mock-answer.mp3",  # This would be a real audio file URL in production
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/similar/{doc_id}", response_model=List[SourceChunk])
async def get_similar_chunks(
    doc_id: str,
    query: str,
    limit: int = Query(5, ge=1, le=20),
):
    """Get document chunks similar to the query."""
    try:
        # Get similar chunks from vector store
        chunks = search_similar_chunks(
            query=query,
            doc_id=doc_id,
            limit=limit,
        )
        
        return chunks
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))